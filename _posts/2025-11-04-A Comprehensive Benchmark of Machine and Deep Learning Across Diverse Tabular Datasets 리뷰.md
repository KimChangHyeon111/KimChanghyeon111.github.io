---
layout: single
title: "A Comprehensive Benchmark of Machine and Deep Learning Across Diverse Tabular Datasets 리뷰"
summary: "A Comprehensive Benchmark of Machine and Deep Learning Across Diverse Tabular Datasets 리뷰"
author: Kim Changhyeon
categories: papers
published: True
toc: True
toc_sticky: True
comments: True
---
## 요약 (Abstract)

이 연구는 과학 연구 및 실제 응용 분야에서 흔히 사용되는 표 형식 데이터 분석에서 기계 학습(ML) 모델과 딥러닝(DL) 모델의 성능을 비교하는 포괄적인 벤치마크를 제시함. 기존 연구들에서 DL 모델은 종종 기존 ML 모델(예: GBMs)보다 성능이 동등하거나 열등한 것으로 나타났기 때문에, 주요 목표는 DL 모델이 우수한 성능을 보이는 데이터셋 유형을 더 잘 특성화하는 것.

*   **범위:** 회귀 및 분류 작업을 포함하는 **111개 데이터셋**과 **20가지 모델**을 평가했으며, 이 데이터셋들은 규모가 다양하고 범주형 변수를 포함하고 있음.
*   **메타 학습:** 벤치마크 결과를 바탕으로, DL 모델이 다른 대안적인 방법들보다 성능이 우수할 시나리오를 예측하는 모델을 훈련하여 **86.1%의 정확도 (AUC 0.78)**를 달성했음.

## 1. 서론 (Introduction)

표 형식 데이터 처리 시 전통적인 ML 알고리즘(예: Random Forest, XGboost)이 오랫동안 DL보다 우수하다고 여겨져 왔음. 하지만 DL 모델이 ML 방법을 능가하는 시나리오가 존재하며, 이러한 고급 기술의 잠재력을 활용하기 위해서는 DL 모델이 우수해지는 조건을 이해하는 것이 중요함.

기존 벤치마킹 연구들은 CatBoost나 XGboost 같은 트리 기반 모델이 DL 모델을 능가한다고 결론지었음. 본 논문은 이러한 격차를 해소하기 위해 111개의 데이터셋을 대상으로 광범위한 벤치마크를 수행했으며, DL 기반 모델 7개, 트리 기반 앙상블(TE) 모델 7개, 기타 ML 모델 6개를 포함하여 총 20개의 모델 구성을 평가했음.

주요 기여 사항으로는 적은 수의 행, 많은 수의 열, 그리고 높은 첨도(kurtosis)와 같은 데이터셋 특징이 DL 모델을 선호한다는 점을 확인한 것임.

## 2. 실험 설정 (Experimental Setup)

이 섹션은 DL 모델이 ML 모델을 능가하는 시점을 탐색하기 위한 실험 구성을 공식적으로 설명함.

### 2.1 데이터셋 (Datasets)

*   **규모 및 구성:** 총 **111개**의 데이터셋(회귀 57개, 분류 54개)을 포함하며, 행 수(43개에서 245,057개)와 열 수(4개에서 267개)에서 상당한 다양성을 보임.
*   **특징:** 현실 세계의 복잡성을 반영하기 위해 범주형 특성을 포함하는 데이터셋을 우선적으로 선정했음.
*   **출처:** 데이터셋의 76%(84개)는 OpenML에서, 18%(20개)는 Materials Science 회귀 벤치마크에서, 6%(7개)는 Kaggle에서 얻었음.

다음은 데이터셋 변수의 기술 통계 표임.

| 변수 | 평균 (Mean) | 표준편차 (STD) | 최소 (Min) | 25% | 중앙값 (Median) | 75% | 최대 (Max) |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| 행 수 (Number of Rows) | 18576 | 39874 | 43 | 673.75 | 4720 | 14057.5 | 245057 |
| 열 수 (Number of Columns) | 24.16 | 40.53 | 4 | 8.75 | 12.5 | 22.25 | 267 |
| 범주형 열 수 (Number of Categorical Columns) | 9.91 | 24.76 | 0 | 1 | 4 | 9 | 231 |
| Kurtosis (첨도) | 348.01 | 1129.66 | -2711.83 | -0.31 | 6.44 | 684.99 | 8901.75 |

### 2.2 머신러닝 및 딥러닝 모델 (Machine learning and deep learning models)

총 20개의 ML 및 DL 모델이 분석에 사용되었음.

*   **트리 기반 앙상블 모델 (TE):** XGBoost, Random Forest, CatBoost, LightGBM, H2O-GBM, AdaBoost, TPOT. (총 7개)
*   **DL 모델:** AutoGluon-DL, H2O-DL, ResNet, MLP, DCNV2, FT-Transformer, TabNet. (총 7개)
*   **기타 모델:** AutoGluon (DL 제한 없음), SVM, KNN, Decision Tree, Symbolic Regression (GPLearn), Linear/Logistic Regression (LR). (총 6개)

### 2.3 평가 전략 (Evaluation strategy)

모델 평가는 10-겹 교차 검증의 평균 결과를 제시함.

*   **회귀 작업:** RMSE, MAE, 결정 계수 ($R^2$)를 사용했음.
*   **분류 작업:** 정확도, AUC, $F_1$ 점수를 사용했음.

### 2.4 메타 분석 프로파일링 (Meta-analysis profiling)

DL 모델이 ML 모델보다 우수한 데이터셋을 분석하기 위해 메타 학습 접근 방식을 채택했음.

*   **메타 데이터셋 구축:** 각 데이터셋을 레코드 수, 특징 수, Kurtosis 등 20개의 매개변수를 가진 메타 특징 벡터($\bar{X}$)로 변환했음.
*   **타겟 변수 설정:** 20개 알고리즘 중 최고 성능 모델이 ML 알고리즘 그룹에 속하면 타겟 변수($\bar{Y}$)를 1로, 그렇지 않으면 0으로 설정하는 이진 분류 문제로 정의했음.
*   **메타 학습 모델:** 이진 분류를 해결하기 위해 로지스틱 회귀 모델(설명 가능성)과 H2O-DL 모델을 사용했음.

## 3. 결과 (Results)

### 3.1 모델 순위 (Model Ranking)

전반적으로 ML 모델이 DL 모델보다 우세한 성능을 보였음.

*   **전체 모델 순위:** ML과 DL 모델의 앙상블 방법인 **AutoGluon**이 전체 111개 데이터셋 중 39개(35%)에서 최고 성능을 달성하여 압도적인 선두를 차지했음.
*   **TE vs DL 순위:** TE 모델이 DL 모델보다 전반적으로 우수했으며, CatBoost가 19개의 데이터셋에서 최고 성능을 달성하며 TE 그룹을 이끌었음.
*   TabNet과 FT-Transformer는 최고 성능을 달성한 데이터셋이 없었으며, TabNet은 모든 모델 중 최악의 평균 순위를 기록했음.

#### TE 및 DL 모델의 성능 순위 표

| Model | Group | # Best (최고 성능 데이터셋 수) | Average Rank (평균 순위) | Median Rank (중앙값 순위) | # in Top 3 Models (Top 3 모델인 횟수) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| CatBoost | TE | 19 | 4.9 | 4 | 50 |
| LightGBM | TE | 15 | 5 | 4 | 47 |
| H2O-GBM | TE | 13 | 7 | 6 | 28 |
| Random Forest | TE | 11 | 6.7 | 6.5 | 28 |
| AutoGluon-DL | DL | 11 | 6.6 | 7 | 32 |
| ResNet | DL | 10 | 7.5 | 8 | 23 |

*   **소규모 데이터셋 영향:** 1000행 미만인 소규모 데이터셋(36개)만 분석했을 때, TE 모델인 H2O-GBM이 6개로 1위였으나, DL 모델인 ResNet이 5개로 근소한 차이로 2위를 차지하며 상대적 성능이 개선되는 경향을 보였음.

### 3.2 메타 분석 프로파일링 (Meta-Analysis Profiling)

DL/ML 모델 간 성능 차이가 통계적으로 유의미한(p < 0.05) 36개 데이터셋에 대해 DL 우세 예측 모델을 훈련했음.

*   **예측 성능:** H2O-DL 모델은 AUC 0.78, 정확도 86.1%를 달성하여 높은 예측 성능을 제공했음.
*   **로지스틱 회귀 분석:** 설명 가능한 모델인 로지스틱 회귀 분석 결과, DL 모델의 우세를 예측하는 데 통계적으로 유의미한 영향을 미치는 두 가지 핵심 특징이 밝혀졌음.

다음은 DL이 ML보다 우세할 확률을 예측하는 로지스틱 회귀 모델 계수 표임.

| Variable | Coefficient (계수) | P-value | 해석 |
| :--- | :--- | :--- | :--- |
| Intercept | -0.8751 | 0.0002 | 통계적으로 매우 유의미함. |
| Classification/Regression | **0.5563** | **0.0317** | 분류 작업일 때 DL의 상대적 성능이 회귀 작업보다 더 좋음. |
| Kurtosis (첨도) | **0.8975** | **0.0244** | Kurtosis가 높을수록 DL이 ML보다 우세할 확률이 통계적으로 유의미하게 증가함. |
| PCA | 0.4624 | 0.0808 | 통계적으로 유의미성에 근접했으며 긍정적인 영향을 보였음. |

*   **데이터 크기 영향 (히트맵):** 로지스틱 회귀 모델 기반의 히트맵 분석은 적은 수의 행과 많은 수의 열이 DL 모델이 ML 모델을 능가할 확률을 높이는 경향을 명확히 보여주었음. 그러나 행 수가 증가함에 따라 이러한 효과는 상대적으로 빠르게 감소했음.
*   **Symbolic Regression (SR):** SR 모델 역시 DL의 상대적 성공률이 작은 데이터셋($x_{\text{row\_count}}$ 항이 음수)과 높은 Kurtosis 값($x_{\text{kurtosis}}$ 항이 양수)에서 높다고 예측하는 수식을 도출했음.

## 4. 논의 (Discussion)

이 연구는 표 형식 데이터에서 DL 모델이 여전히 ML 모델, 특히 트리 기반 앙상블 모델에 의해 평균적으로 성능이 떨어진다는 것을 재확인했음. 다만, AutoGluon과 같은 앙상블 자동 ML 모델이 가장 우수한 성능을 보였음.

*   **DL/ML 성능 격차:** ML 모델이 무작위 표 형식 데이터셋에서 '안전한 선택'임을 시사하며, 특히 TabNet과 같은 표 형식 데이터 전용 DL 모델조차 MLP와 같은 범용 DL 모델보다 성능이 낮았음.
*   **데이터 특성 영향:**
    *   **작업 유형:** DL 모델의 상대적 성능은 **분류 작업**에서 더 좋음. 이는 회귀 작업의 RMSE 메트릭이 큰 오류에 무거운 패널티를 부과하는 반면, DL 모델이 넓은 매개변수 공간으로 인해 때때로 큰 오류를 보일 수 있기 때문임. 
    *   **Kurtosis:** 큰 Kurtosis 값은 DL 모델의 우세를 예측하는 통계적으로 유의미한 변수임. 이는 큰 Kurtosis가 '긴 꼬리 분포'를 나타내며, DL 모델이 이러한 분포에서 ML 모델보다 뛰어난 성능을 발휘하는 경향이 있기 때문임.
    *   **데이터 크기:** 적은 행 수와 많은 열 수가 DL 모델의 우세 확률을 높이는 경향이 있었지만, 데이터 크기 자체가 유일한 결정 요인은 아님을 확인했음.

#### 느낀 점
1. 언제적 gbdt냐 라기에는 아직도 그 이상이 없다는게 좀 신기함.
